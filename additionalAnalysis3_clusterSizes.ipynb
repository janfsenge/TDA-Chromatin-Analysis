{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e439442c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gudhi as gd\n",
    "from scipy.ndimage import label, gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e337a0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gudhi as gd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.ndimage import gaussian_filter, generate_binary_structure\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.inputreader import read_segmented_images, persistence_writer_ensure_filesize\n",
    "from src.inputreader import read_persistence_files\n",
    "from src.auxfunctions import compute_vectorizations_all\n",
    "from src.auxfunctions import get_all_classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3c827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ball_structure(radius):\n",
    "    \"\"\"\n",
    "    Create a 3D ball structure of a given radius and trim it to remove all-False outer layers.\n",
    "\n",
    "    Parameters:\n",
    "    radius (float): The radius of the ball.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: A 3D boolean array representing the trimmed ball structure.\n",
    "    \"\"\"\n",
    "    # Determine the size of the array based on the radius\n",
    "    size = int(2 * np.ceil(radius) + 1)\n",
    "\n",
    "    # Create a grid of coordinates\n",
    "    x, y, z = np.indices((size, size, size))\n",
    "\n",
    "    # Calculate the distance from the center\n",
    "    center = np.array([(size - 1) / 2, (size - 1) / 2, (size - 1) / 2])\n",
    "    distance = np.sqrt((x - center[0])**2 + (y - center[1])**2 + (z - center[2])**2)\n",
    "\n",
    "    # Create the ball structure\n",
    "    ball_structure = distance <= radius\n",
    "\n",
    "    # Trim the structure to remove all-False outer layers\n",
    "    while np.all(~ball_structure[0, :, :]):\n",
    "        ball_structure = ball_structure[1:, :, :]\n",
    "    while np.all(~ball_structure[:, 0, :]):\n",
    "        ball_structure = ball_structure[:, 1:, :]\n",
    "    while np.all(~ball_structure[:, :, 0]):\n",
    "        ball_structure = ball_structure[:, :, 1:]\n",
    "    while np.all(~ball_structure[-1, :, :]):\n",
    "        ball_structure = ball_structure[:-1, :, :]\n",
    "    while np.all(~ball_structure[:, -1, :]):\n",
    "        ball_structure = ball_structure[:, :-1, :]\n",
    "    while np.all(~ball_structure[:, :, -1]):\n",
    "        ball_structure = ball_structure[:, :, :-1]\n",
    "\n",
    "    return ball_structure\n",
    "\n",
    "def label_cubical_complex_3d(array_3d, structuresize=3):\n",
    "    \"\"\"\n",
    "    Label a 3D array with the same connectivity as Gudhi's cubical complex (8-neighborhood in 3D).\n",
    "\n",
    "    Parameters:\n",
    "    array_3d (numpy.ndarray): A 3D binary array where features to be labeled are True or 1.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: A labeled array where each feature has a unique label.\n",
    "    \"\"\"\n",
    "    # Define the connectivity structure for 8-neighborhood in 3D\n",
    "    structure = np.ones((structuresize, structuresize, structuresize), dtype=bool)\n",
    "\n",
    "    # Label the features in the array\n",
    "    labeled_array, num_features = label(array_3d, structure=structure)\n",
    "\n",
    "    return labeled_array, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43ff12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input = Path('data_segmented')\n",
    "input_airyscan = data_input / 'Airyscan'\n",
    "input_sted = data_input / 'STED'\n",
    "\n",
    "data_pers = Path('data_processed')\n",
    "\n",
    "pers_sted = data_pers / 'persistence_sted'\n",
    "pers_airyscan = data_pers / 'persistence_airyscan'\n",
    "pers_sted_other = data_pers / 'persistence_sted' / 'other_preprocessing'\n",
    "pers_airyscan_other = data_pers / 'persistence_airyscan' / 'other_preprocessing'\n",
    "\n",
    "vec_sted = data_pers / 'vectorizations_sted'\n",
    "vec_airyscan = data_pers / 'vectorizations_airyscan'\n",
    "vec_sted_other = data_pers / 'vectorizations_sted' / 'other_preprocessing'\n",
    "vec_airyscan_other = data_pers / 'vectorizations_airyscan' / 'other_preprocessing'\n",
    "\n",
    "classification_path_preproc = data_pers / 'classification' / 'preprocessing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4343f772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get the metadata for the original files as well as the segmented files\n",
    "# df_sted_metadata = pd.read_csv(data_input/ 'sted_df_metadata.csv', comment='#')\n",
    "\n",
    "# masks, bounding_boxes, labels_str, labels, npzfiles = \\\n",
    "#     read_segmented_images(input_sted, microscope='sted', replace_nan_with=0)\n",
    "\n",
    "# df_labels = pd.DataFrame(labels_str, columns=['labels_str'])\n",
    "# df_labels.loc[:, 'labels'] = labels\n",
    "# df_labels.loc[:, 'id'] = np.arange(len(labels))\n",
    "# df_labels.loc[:, 'microscope'] = 'sted'\n",
    "# df_labels.loc[:, 'filename'] = [f.name for f in npzfiles]\n",
    "# df_labels.to_csv(Path(data_pers, 'labels_persistence_sted.csv'),\n",
    "#                  index=False)\n",
    "\n",
    "# # get the physical pixel sizes for each image\n",
    "# for filename in npzfiles:\n",
    "#     assert len(df_sted_metadata.loc[df_sted_metadata['segmented_filename'] == filename.name, :]) == 1\n",
    "# pixelsizes = [df_sted_metadata.loc[df_sted_metadata['segmented_filename'] == filename.name,\n",
    "#                                    ['pixel_size_z', 'pixel_size_x', 'pixel_size_y']]\\\n",
    "#                                     .values[0] for filename in npzfiles]\n",
    "# pixelsizes = np.array(pixelsizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08328e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airy_metadata = pd.read_csv(data_input / 'airyscan_df_metadata.csv')\n",
    "masks, bounding_boxes, labels_str, labels, npzfiles = read_segmented_images(input_airyscan, microscope='airyscan')\n",
    "\n",
    "df_labels = pd.DataFrame(labels_str, columns=['labels_str'])\n",
    "df_labels.loc[:, 'labels'] = labels\n",
    "df_labels.loc[:, 'id'] = np.arange(len(labels))\n",
    "df_labels.loc[:, 'microscope'] = 'airyscan'\n",
    "df_labels.loc[:, 'filename'] = [f.name for f in npzfiles]\n",
    "\n",
    "df_labels.to_csv(Path(data_pers, 'labels_persistence_airyscan.csv'),\n",
    "                 index=False)\n",
    "\n",
    "pixelsizes = [df_airy_metadata.loc[df_airy_metadata['segmented_filename'] == filename.name,\n",
    "              ['pixel_size_z', 'pixel_size_x', 'pixel_size_y']]\\\n",
    "              .values[0] for filename in npzfiles]\n",
    "pixelsizes = np.array(pixelsizes)\n",
    "\n",
    "assert np.all(pixelsizes[:, 1] == pixelsizes[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee5084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = 'clip_minmax_gaussian4a_minmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd3605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1\n",
    "\n",
    "filtered_images = []\n",
    "for i, mask_loop in tqdm(enumerate(masks), total=len(masks)):\n",
    "    mask = mask_loop.astype(np.float64)\n",
    "    if np.any(np.isnan(mask)):\n",
    "        assert np.nanmin(mask) == 0\n",
    "        mask[np.isnan(mask)] = 0\n",
    "    mask_org = mask.copy()\n",
    "\n",
    "    # if preproc != 'raw':\n",
    "    #     quant05 = np.nanquantile(mask[mask > np.min(mask)], 0.05)\n",
    "    #     quant95 = np.nanquantile(mask[mask > np.min(mask)], 0.95)\n",
    "    #     mask = np.clip(mask, quant05, quant95)\n",
    "    \n",
    "    # if 'clip_minmax' in preproc:\n",
    "    #     mask = MinMaxScaler().fit_transform(mask.reshape(-1, 1)).reshape(mask.shape)\n",
    "    \n",
    "    if 'gaussian' in preproc and ('a_minmax' in preproc or 'a_mask0' in preproc or preproc.endswith('a')):\n",
    "        sigma_pixels = 1\n",
    "    elif 'gaussian' in preproc and ('b_minmax' in preproc or 'b_mask0' in preproc or preproc.endswith('b')):\n",
    "        # set the sigmas such that pixel_x and pixel_y are 1\n",
    "        sigma_pixels = pixelsizes[i].copy()\n",
    "        # x and y resolution should be the same\n",
    "        assert sigma_pixels[1] == sigma_pixels[2]\n",
    "        sigma_pixels /= sigma_pixels[1]\n",
    "    elif 'gaussian' in preproc and ('c_minmax' in preproc or 'c_mask0' in preproc or preproc.endswith('c')):\n",
    "        # set the sigmas such that pixel_z are 1\n",
    "        sigma_pixels = pixelsizes[i].copy()\n",
    "        # x and y resolution should be the same\n",
    "        assert sigma_pixels[1] == sigma_pixels[2]\n",
    "        sigma_pixels /= sigma_pixels[0]\n",
    "    \n",
    "    if 'gaussian' in preproc:\n",
    "        gaussian_truncate = \\\n",
    "            int(preproc[preproc.find('gaussian') + len('gaussian'):].split('_')[0][:-1])\n",
    "        mask = gaussian_filter(mask, sigma=sigma_pixels,\n",
    "                truncate=gaussian_truncate, mode='constant', cval=0.0)\n",
    "    \n",
    "    filtered_images.append(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccc475f",
   "metadata": {},
   "source": [
    "# for a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3929b270",
   "metadata": {},
   "outputs": [],
   "source": [
    "## THIS TAKES SUPER LONG\n",
    "\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "\n",
    "# labelled, numfeats = label_cubical_complex_3d(image_binary)\n",
    "# distances = np.zeros([numfeats, numfeats])\n",
    "\n",
    "# for feat in tqdm(range(1, numfeats)):\n",
    "#     image_oneregion = labelled != feat\n",
    "#     disttemp = distance_transform_edt(image_oneregion, sampling=(1, 1, 1), return_distances=True)\n",
    "\n",
    "#     # sigma_pixels = pixelsizes[i].copy()\n",
    "#     # sigma_pixels /= sigma_pixels[1]\n",
    "#     # disttemp = distance_transform_edt(image_oneregion, sampling=sigma_pixels, return_distances=True)\n",
    "\n",
    "#     for feat2 in range(feat+1, numfeats):\n",
    "#         distances[feat, feat2] = np.min(disttemp[labelled == feat2])\n",
    "#         distances[feat2, feat] = distances[feat, feat2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f535485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# values = []\n",
    "# for thresh in tqdm(np.linspace(np.min(mask), np.max(mask), 100, endpoint=False)):\n",
    "#     labeled, numfeats = label(mask >= thresh, structure=generate_binary_structure(3, 2))\n",
    "#     values.append([thresh, numfeats])\n",
    "\n",
    "# values = np.array(values)\n",
    "\n",
    "# plt.plot(values[:, 0], values[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3d3c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import distance_transform_edt, binary_dilation, label\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "def compute_region_distances(labeled_array, intersecting_labels):\n",
    "    distances_tmp = np.zeros((len(intersecting_labels), len(intersecting_labels)))\n",
    "    for i, labelA in enumerate(intersecting_labels):\n",
    "        # Compute the distance transform for the current region\n",
    "        dist_mask = distance_transform_edt(~(labeled_array == labelA), return_distances=True)\n",
    "\n",
    "        for j, labelB in enumerate(intersecting_labels[i+1:]):\n",
    "            # Compute the minimum distance between the two regions\n",
    "            min_distance = np.min(dist_mask[labeled_array == labelB])\n",
    "            distances_tmp[i, j+i+1] = min_distance\n",
    "            distances_tmp[j+i+1, i] = min_distance\n",
    "    \n",
    "    return distances_tmp\n",
    "\n",
    "def find_regions_within_distance_optimized(labeled_array, N):\n",
    "    \"\"\"\n",
    "    Find all regions in a labeled array that are within a distance of N pixels from each other using EDT and dilation.\n",
    "\n",
    "    Parameters:\n",
    "    labeled_array (numpy.ndarray): A labeled array where each region has a unique label.\n",
    "    N (int): The maximum distance in pixels.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are region labels and values are lists of region labels within distance N.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize a dictionary to store the regions within distance N\n",
    "    regions_within_distance = {}\n",
    "\n",
    "    # Create a labeled dilation mask\n",
    "    dilated_region = binary_dilation(labeled_array > 0,\n",
    "                        structure=np.ones((3, 3, 3)),\n",
    "                        iterations=N)\n",
    "    labeled_dilation_mask, numfeats = label(dilated_region, structure=generate_binary_structure(3, 2))\n",
    "\n",
    "    # Check for intersections between dilated masks\n",
    "    for label1 in range(1, numfeats + 1):\n",
    "        # Find other regions that intersect with the dilated mask\n",
    "        intersecting_labels = np.unique(labeled_array[labeled_dilation_mask == label1])\n",
    "        intersecting_labels = intersecting_labels[intersecting_labels != 0]\n",
    "\n",
    "        distances = compute_region_distances(labeled_array, intersecting_labels)\n",
    "\n",
    "        for label_in in intersecting_labels:\n",
    "            if label_in in regions_within_distance:\n",
    "                print(f\"Label {label_in} is already in?\")\n",
    "\n",
    "            if len(intersecting_labels) > 1:\n",
    "                regions_within_distance[label_in] = (list(intersecting_labels), squareform(distances))\n",
    "            assert len(intersecting_labels) > 0, f'{np.unique(labeled_array[labeled_dilation_mask == label1])}'\n",
    "        \n",
    "\n",
    "    return regions_within_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4fd533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from skimage.measure import regionprops\n",
    "from scipy.ndimage import generate_binary_structure, label\n",
    "from tqdm import tqdm\n",
    "\n",
    "minval = np.min([np.min(mask) for mask in filtered_images])\n",
    "maxval = np.max([np.max(mask) for mask in filtered_images])\n",
    "median = np.mean([np.quantile(mask, 0.5) for mask in filtered_images])\n",
    "\n",
    "numberfeatures = []\n",
    "smalldistances = []\n",
    "totalsizes = []\n",
    "sizes = []\n",
    "thresholds = list(np.linspace(minval, median, 25, endpoint=False)[1:])\\\n",
    "    + list(np.linspace(median, maxval, 75, endpoint=False))\n",
    "\n",
    "for maski, mask in tqdm(enumerate(filtered_images)):\n",
    "    numfeats = []\n",
    "    smalldist = []\n",
    "    size = []\n",
    "    totalsize = []\n",
    "\n",
    "    for thresh in tqdm(thresholds):\n",
    "        labeled, numfeat = label(mask >= thresh, structure=generate_binary_structure(3, 2))\n",
    "        numfeats.append(numfeat)\n",
    "\n",
    "        smalldist.append(find_regions_within_distance_optimized(labeled, 10))\n",
    "        size.append([int(region.area) for region in regionprops(labeled)])\n",
    "        totalsize.append(np.count_nonzero(masks[maski] > np.min(masks[maski])))\n",
    "\n",
    "    numberfeatures.append(numfeats)\n",
    "    smalldistances.append(smalldist)\n",
    "    totalsizes.append(totalsize)\n",
    "    sizes.append(size)\n",
    "\n",
    "# Dump everything into a single pickle file\n",
    "data_to_pickle = {\n",
    "    \"numberfeatures\": numberfeatures,\n",
    "    \"smalldistances\": smalldistances,\n",
    "    \"totalsizes\": totalsizes,\n",
    "    \"sizes\": sizes,\n",
    "    \"thresholds\": thresholds\n",
    "}\n",
    "\n",
    "with open(\"region_data.pkl\", \"wb\") as file:\n",
    "    pickle.dump(data_to_pickle, file)\n",
    "\n",
    "print(\"Data successfully saved to region_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf96d5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump everything into a single pickle file\n",
    "data_to_pickle = {\n",
    "    \"numberfeatures\": numberfeatures,\n",
    "    \"smalldistances\": smalldistances,\n",
    "    \"totalsizes\": totalsizes,\n",
    "    \"sizes\": sizes,\n",
    "    \"thresholds\": thresholds\n",
    "}\n",
    "\n",
    "with open(\"region_data_airyscan.pkl\", \"wb\") as file:\n",
    "    pickle.dump(data_to_pickle, file)\n",
    "\n",
    "print(\"Data successfully saved to region_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e93ab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the metadata for the original files as well as the segmented files\n",
    "df_sted_metadata = pd.read_csv(data_input/ 'sted_df_metadata.csv', comment='#')\n",
    "\n",
    "masks, bounding_boxes, labels_str, labels, npzfiles = \\\n",
    "    read_segmented_images(input_sted, microscope='sted', replace_nan_with=0)\n",
    "\n",
    "df_labels = pd.DataFrame(labels_str, columns=['labels_str'])\n",
    "df_labels.loc[:, 'labels'] = labels\n",
    "df_labels.loc[:, 'id'] = np.arange(len(labels))\n",
    "df_labels.loc[:, 'microscope'] = 'sted'\n",
    "df_labels.loc[:, 'filename'] = [f.name for f in npzfiles]\n",
    "df_labels.to_csv(Path(data_pers, 'labels_persistence_sted.csv'),\n",
    "                 index=False)\n",
    "\n",
    "# get the physical pixel sizes for each image\n",
    "for filename in npzfiles:\n",
    "    assert len(df_sted_metadata.loc[df_sted_metadata['segmented_filename'] == filename.name, :]) == 1\n",
    "pixelsizes = [df_sted_metadata.loc[df_sted_metadata['segmented_filename'] == filename.name,\n",
    "                                   ['pixel_size_z', 'pixel_size_x', 'pixel_size_y']]\\\n",
    "                                    .values[0] for filename in npzfiles]\n",
    "pixelsizes = np.array(pixelsizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603e4671",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1\n",
    "\n",
    "filtered_images = []\n",
    "for i, mask_loop in tqdm(enumerate(masks), total=len(masks)):\n",
    "    mask = mask_loop.astype(np.float64)\n",
    "    if np.any(np.isnan(mask)):\n",
    "        assert np.nanmin(mask) == 0\n",
    "        mask[np.isnan(mask)] = 0\n",
    "    mask_org = mask.copy()\n",
    "\n",
    "    # if preproc != 'raw':\n",
    "    #     quant05 = np.nanquantile(mask[mask > np.min(mask)], 0.05)\n",
    "    #     quant95 = np.nanquantile(mask[mask > np.min(mask)], 0.95)\n",
    "    #     mask = np.clip(mask, quant05, quant95)\n",
    "    \n",
    "    # if 'clip_minmax' in preproc:\n",
    "    #     mask = MinMaxScaler().fit_transform(mask.reshape(-1, 1)).reshape(mask.shape)\n",
    "    \n",
    "    if 'gaussian' in preproc and ('a_minmax' in preproc or 'a_mask0' in preproc or preproc.endswith('a')):\n",
    "        sigma_pixels = 1\n",
    "    elif 'gaussian' in preproc and ('b_minmax' in preproc or 'b_mask0' in preproc or preproc.endswith('b')):\n",
    "        # set the sigmas such that pixel_x and pixel_y are 1\n",
    "        sigma_pixels = pixelsizes[i].copy()\n",
    "        # x and y resolution should be the same\n",
    "        assert sigma_pixels[1] == sigma_pixels[2]\n",
    "        sigma_pixels /= sigma_pixels[1]\n",
    "    elif 'gaussian' in preproc and ('c_minmax' in preproc or 'c_mask0' in preproc or preproc.endswith('c')):\n",
    "        # set the sigmas such that pixel_z are 1\n",
    "        sigma_pixels = pixelsizes[i].copy()\n",
    "        # x and y resolution should be the same\n",
    "        assert sigma_pixels[1] == sigma_pixels[2]\n",
    "        sigma_pixels /= sigma_pixels[0]\n",
    "    \n",
    "    if 'gaussian' in preproc:\n",
    "        gaussian_truncate = \\\n",
    "            int(preproc[preproc.find('gaussian') + len('gaussian'):].split('_')[0][:-1])\n",
    "        mask = gaussian_filter(mask, sigma=sigma_pixels,\n",
    "                truncate=gaussian_truncate, mode='constant', cval=0.0)\n",
    "    \n",
    "    filtered_images.append(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea50c134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from skimage.measure import regionprops\n",
    "from scipy.ndimage import generate_binary_structure, label\n",
    "from tqdm import tqdm\n",
    "\n",
    "minval = np.min([np.min(mask) for mask in filtered_images])\n",
    "maxval = np.max([np.max(mask) for mask in filtered_images])\n",
    "median = np.mean([np.quantile(mask, 0.5) for mask in filtered_images])\n",
    "\n",
    "numberfeatures = []\n",
    "smalldistances = []\n",
    "totalsizes = []\n",
    "sizes = []\n",
    "thresholds = list(np.linspace(minval, median, 25, endpoint=False)[1:])\\\n",
    "    + list(np.linspace(median, maxval, 75, endpoint=False))\n",
    "\n",
    "for maski, mask in tqdm(enumerate(filtered_images)):\n",
    "    numfeats = []\n",
    "    smalldist = []\n",
    "    size = []\n",
    "    totalsize = []\n",
    "\n",
    "    for thresh in tqdm(thresholds):\n",
    "        if thresh <= np.min(mask):\n",
    "            continue\n",
    "        labeled, numfeat = label(mask >= thresh, structure=generate_binary_structure(3, 2))\n",
    "        numfeats.append(numfeat)\n",
    "\n",
    "        # smalldist.append(find_regions_within_distance_optimized(labeled, 10))\n",
    "        size.append([int(region.area) for region in regionprops(labeled)])\n",
    "        totalsize.append(np.count_nonzero(masks[maski] > np.min(masks[maski])))\n",
    "\n",
    "    # Dump everything into a single pickle file\n",
    "    data_to_pickle = {\n",
    "        \"numberfeatures\": numfeats,\n",
    "        \"smalldistances\": smalldist,\n",
    "        \"totalsizes\": totalsize,\n",
    "        \"sizes\": size,\n",
    "        \"thresholds\": thresholds\n",
    "    }\n",
    "\n",
    "    # with open(f\"region_data_sted_{maski}.pkl\", \"wb\") as file:\n",
    "    #     pickle.dump(data_to_pickle, file)\n",
    "\n",
    "    numberfeatures.append(numfeats)\n",
    "    smalldistances.append(smalldist)\n",
    "    totalsizes.append(totalsize)\n",
    "    sizes.append(size)\n",
    "\n",
    "# Dump everything into a single pickle file\n",
    "data_to_pickle = {\n",
    "    \"numberfeatures\": numberfeatures,\n",
    "    \"smalldistances\": smalldistances,\n",
    "    \"totalsizes\": totalsizes,\n",
    "    \"sizes\": sizes,\n",
    "    \"thresholds\": thresholds\n",
    "}\n",
    "\n",
    "with open(\"region_data_sted.pkl\", \"wb\") as file:\n",
    "    pickle.dump(data_to_pickle, file)\n",
    "\n",
    "print(\"Data successfully saved to region_data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3a503b",
   "metadata": {},
   "source": [
    "# plot and interpret it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3955a4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_boxplot_quantiles(values):\n",
    "    \"\"\"\n",
    "    Compute the quantiles used for a boxplot.\n",
    "\n",
    "    Parameters:\n",
    "    values (list or numpy.ndarray): A list or array of numerical values.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing the minimum, Q1, median, Q3, and maximum.\n",
    "    \"\"\"\n",
    "    if len(values) == 0:\n",
    "        return []\n",
    "\n",
    "    values = np.array(values)\n",
    "    quantiles = {\n",
    "        'min': np.min(values),\n",
    "        'Q1': np.percentile(values, 25),\n",
    "        'mean': np.mean(values),\n",
    "        'median': np.percentile(values, 50),\n",
    "        'Q3': np.percentile(values, 75),\n",
    "        'max': np.max(values)\n",
    "    }\n",
    "    return list(quantiles.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a1e257",
   "metadata": {},
   "source": [
    "## Airyscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebca0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"region_data_airyscan.pkl\", \"rb\") as file:\n",
    "    data_loaded = pickle.load(file)\n",
    "\n",
    "print(data_loaded)\n",
    "\n",
    "thresholds = data_loaded['thresholds'].copy()\n",
    "numberfeatures = data_loaded['numberfeatures'].copy()\n",
    "smalldistances = data_loaded['smalldistances'].copy()\n",
    "totalsizes = data_loaded['totalsizes'].copy()\n",
    "sizes = data_loaded['sizes'].copy()\n",
    "\n",
    "del data_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f86efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sizes_reordered = [[[] for t in thresholds],\n",
    "#                    [[] for t in thresholds]]\n",
    "# labels_assignment = {}\n",
    "# for i, size in tqdm(enumerate(sizes)):\n",
    "#     for ti, _ in enumerate(thresholds):\n",
    "#         stats = compute_boxplot_quantiles(size[ti])\n",
    "#         if len(stats) > 0:\n",
    "#             sizes_reordered[labels[i]][ti].append(stats)\n",
    "\n",
    "# for i in range(len(sizes_reordered)):\n",
    "#     for ti, _ in enumerate(thresholds):\n",
    "#         if len(sizes_reordered[i][ti]) > 0:\n",
    "#             sizes_reordered[i][ti] = np.array(sizes_reordered[i][ti])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00d7a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = []\n",
    "# for i in range(len(sizes_reordered)):\n",
    "#     for ti, t in enumerate(thresholds):\n",
    "#         if len(sizes_reordered[i][ti]) > 0:\n",
    "#             data.append({\n",
    "#                 'label': i,\n",
    "#                 'thresh': t,\n",
    "#                 'min': sizes_reordered[i][ti][0],\n",
    "#                 'Q1': sizes_reordered[i][ti][1],\n",
    "#                 'mean': sizes_reordered[i][ti][2],\n",
    "#                 'median': sizes_reordered[i][ti][3],\n",
    "#                 'Q3': sizes_reordered[i][ti][4],\n",
    "#                 'max': sizes_reordered[i][ti][5]\n",
    "#             }.copy())\n",
    "# data = pd.DataFrame(data)\n",
    "# df_data = data.groupby(['label', 'thresh']).mean().reset_index()\n",
    "# df_count = data.groupby(['label', 'thresh']).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588c5224",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i, size in tqdm(enumerate(sizes)):\n",
    "    for ti, t in enumerate(thresholds):\n",
    "        # fix the totalsize part, since we want to exclude the minimal image value\n",
    "        if t <= np.min(filtered_images[i]):\n",
    "            continue\n",
    "        stats = compute_boxplot_quantiles(size[ti])\n",
    "        if len(stats) > 0:\n",
    "            data.append({\n",
    "                'pos': i, \n",
    "                'label': labels[i],\n",
    "                'thresh': t,\n",
    "                'min': stats[0],\n",
    "                'Q1': stats[1],\n",
    "                'mean': stats[2],\n",
    "                'median': stats[3],\n",
    "                'Q3': stats[4],\n",
    "                'max': stats[5],\n",
    "                'count': len(size[ti])\n",
    "            }.copy())\n",
    "\n",
    "data = pd.DataFrame(data)\n",
    "data.loc[:, 'totalsize'] = [np.count_nonzero(filtered_images[i] > np.min(filtered_images[i]))\n",
    "                            for i in data['pos'].values]\n",
    "df_data = data.groupby(['label', 'thresh']).mean().reset_index()\n",
    "df_count = data.groupby(['label', 'thresh']).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45699a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datarel = data.copy()\n",
    "for col in ['min', 'Q1', 'mean', 'median', 'Q3', 'max']:\n",
    "    df_datarel[col] = df_datarel[col].astype(np.float64) \n",
    "    df_datarel[col] = df_datarel[col] / df_datarel['totalsize'].astype(np.float64)\n",
    "    \n",
    "# df_datarel = df_datarel.groupby(['label', 'thresh']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73841a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshidx = set(df_count.loc[(df_count['mean'] > 1) & (df_count['label'] == 0), 'thresh'].values).\\\n",
    "    intersection(set(df_count.loc[(df_count['mean'] > 1) & (df_count['label'] == 0), 'thresh'].values))\n",
    "\n",
    "df_count.loc[df_count['thresh'].isin(threshidx), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a800e9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the mean line\n",
    "fig, ax  = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "threshlimit = [0, 0]\n",
    "for i in range(2):\n",
    "    largest_diff = np.argmax(np.diff(df_data.loc[(df_data['label']==i) & (df_data['thresh'].isin(threshidx)), 'mean'].values))\n",
    "    threshlimit[i] = df_data.loc[(df_data['label']==i) & (df_data['thresh'].isin(threshidx)), 'thresh'].values[largest_diff:largest_diff+1][0]\n",
    "threshlimit = np.mean(threshlimit)\n",
    "\n",
    "df = df_data.loc[(df_data['thresh'] < threshlimit) & (df_data['thresh'].isin(threshidx))]\n",
    "sns.lineplot(data=df, x='thresh', y='mean', hue='label', marker='o', ax=ax[0])\n",
    "\n",
    "# Add error bars for IQR\n",
    "for label in df['label'].unique():\n",
    "    subset = df[df['label'] == label]\n",
    "    ax[0].errorbar(subset['thresh'], subset['mean'],\n",
    "                 yerr=[subset['Q1'], subset['Q3']],\n",
    "                 fmt='o', capsize=5, color=sns.color_palette()[df['label'].unique().tolist().index(label)],\n",
    "                 alpha=0.5)\n",
    "\n",
    "# Mark min and max as outliers\n",
    "for label in df['label'].unique():\n",
    "    subset = df[df['label'] == label]\n",
    "    ax[0].scatter(subset['thresh'], subset['min'], color='red', marker='_', s=100, label='Min' if label == df['label'].unique()[0] else \"\")\n",
    "    ax[0].scatter(subset['thresh'], subset['max'], color='red', marker='_', s=100, label='Max' if label == df['label'].unique()[0] else \"\")\n",
    "\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].set_title('Lineplot with IQR Error Bars and Min/Max Outliers')\n",
    "ax[0].legend()\n",
    "\n",
    "df = df_data.loc[df_data['thresh'] >= threshlimit]\n",
    "sns.lineplot(data=df, x='thresh', y='mean', hue='label', marker='o', ax=ax[1])\n",
    "\n",
    "# Add error bars for IQR\n",
    "for label in df['label'].unique():\n",
    "    subset = df[df['label'] == label]\n",
    "    ax[1].errorbar(subset['thresh'], subset['mean'],\n",
    "                 yerr=[subset['Q1'], subset['Q3']],\n",
    "                 fmt='o', capsize=5, color=sns.color_palette()[df['label'].unique().tolist().index(label)],\n",
    "                 alpha=0.5)\n",
    "\n",
    "# Mark min and max as outliers\n",
    "for label in df['label'].unique():\n",
    "    subset = df[df['label'] == label]\n",
    "    ax[1].scatter(subset['thresh'], subset['min'], color='red', marker='_', s=100, label='Min' if label == df['label'].unique()[0] else \"\")\n",
    "    ax[1].scatter(subset['thresh'], subset['max'], color='red', marker='_', s=100, label='Max' if label == df['label'].unique()[0] else \"\")\n",
    "\n",
    "ax[1].set_yscale('log')\n",
    "ax[1].set_title('Lineplot with IQR Error Bars and Min/Max Outliers')\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0d3832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the mean line\n",
    "fig, ax  = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "threshlimit = [0, 0]\n",
    "for i in range(2):\n",
    "    largest_diff = np.argmax(np.diff(df_datarel.loc[(df_datarel['label']==i) & (df_datarel['thresh'].isin(threshidx)), 'mean'].values))\n",
    "    threshlimit[i] = df_datarel.loc[(df_datarel['label']==i) & (df_datarel['thresh'].isin(threshidx)), 'thresh'].values[largest_diff:largest_diff+1][0]\n",
    "threshlimit = np.mean(threshlimit)\n",
    "\n",
    "df = df_datarel.loc[(df_datarel['thresh'] < threshlimit) & (df_datarel['thresh'].isin(threshidx))]\n",
    "sns.lineplot(data=df, x='thresh', y='mean', hue='label', marker='o', ax=ax[0])\n",
    "\n",
    "# Add error bars for IQR\n",
    "for label in df['label'].unique():\n",
    "    subset = df[df['label'] == label]\n",
    "    ax[0].errorbar(subset['thresh'], subset['mean'],\n",
    "                 yerr=[subset['Q1'], subset['Q3']],\n",
    "                 fmt='o', capsize=5, color=sns.color_palette()[df['label'].unique().tolist().index(label)],\n",
    "                 alpha=0.5)\n",
    "\n",
    "# Mark min and max as outliers\n",
    "for label in df['label'].unique():\n",
    "    subset = df[df['label'] == label]\n",
    "    ax[0].scatter(subset['thresh'], subset['min'], color='red', marker='_', s=100, label='Min' if label == df['label'].unique()[0] else \"\")\n",
    "    ax[0].scatter(subset['thresh'], subset['max'], color='red', marker='_', s=100, label='Max' if label == df['label'].unique()[0] else \"\")\n",
    "\n",
    "# ax[0].set_yscale('log')\n",
    "ax[0].set_title('Lineplot with IQR Error Bars and Min/Max Outliers')\n",
    "ax[0].legend()\n",
    "\n",
    "df = df_datarel.loc[df_datarel['thresh'] >= threshlimit]\n",
    "sns.lineplot(data=df, x='thresh', y='mean', hue='label', marker='o', ax=ax[1])\n",
    "\n",
    "# Add error bars for IQR\n",
    "for label in df['label'].unique():\n",
    "    subset = df[df['label'] == label]\n",
    "    ax[1].errorbar(subset['thresh'], subset['mean'],\n",
    "                 yerr=[subset['Q1'], subset['Q3']],\n",
    "                 fmt='o', capsize=5, color=sns.color_palette()[df['label'].unique().tolist().index(label)],\n",
    "                 alpha=0.5)\n",
    "\n",
    "# Mark min and max as outliers\n",
    "for label in df['label'].unique():\n",
    "    subset = df[df['label'] == label]\n",
    "    ax[1].scatter(subset['thresh'], subset['min'], color='red', marker='_', s=100, label='Min' if label == df['label'].unique()[0] else \"\")\n",
    "    ax[1].scatter(subset['thresh'], subset['max'], color='red', marker='_', s=100, label='Max' if label == df['label'].unique()[0] else \"\")\n",
    "\n",
    "# ax[1].set_yscale('log')\n",
    "ax[1].set_title('Lineplot with IQR Error Bars and Min/Max Outliers')\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab63d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "sns.lineplot(data=df_datarel, x='thresh', y='mean', hue='label', ax=ax)\n",
    "\n",
    "# Add a twin axis\n",
    "ax2 = ax.twinx()\n",
    "sns.lineplot(data=df_data, x='thresh', y='count', hue='label', ax=ax2, linestyle='--')\n",
    "\n",
    "# Customize the labels for clarity\n",
    "ax.set_ylabel('Mean')\n",
    "ax2.set_ylabel('Count')\n",
    "ax.set_xlabel('Threshold')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503e2b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plotnew = df_data[['label', 'thresh', 'median', 'count']].groupby(['label', 'thresh']).\\\n",
    "    aggregate('median').reset_index()\n",
    "df_plotnew1 = df_data[['label', 'thresh', 'median', 'count']].groupby(['label', 'thresh']).\\\n",
    "    aggregate(lambda x: np.quantile(x, 0.75)).reset_index()\n",
    "df_plotnew2 = df_data[['label', 'thresh', 'median', 'count']].groupby(['label', 'thresh']).\\\n",
    "    aggregate(lambda x: np.quantile(x, 0.25)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476f3879",
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals = df_plotnew.loc[df_plotnew['label'] == 0, 'thresh'].values\n",
    "yvals = df_plotnew.loc[df_plotnew['label'] == 0, 'median'].values\n",
    "\n",
    "y1 = df_plotnew1.loc[df_plotnew1['label'] == 0, 'median'].values\n",
    "y2 = df_plotnew2.loc[df_plotnew2['label'] == 0, 'median'].values\n",
    "\n",
    "plt.plot(xvals, yvals, label='Label 0', lw=1.5, color='red')\n",
    "plt.fill_between(xvals, y1, y2, alpha=0.3, label='IQR for Label 0', color='red')\n",
    "\n",
    "xvals = df_plotnew.loc[df_plotnew['label'] == 1, 'thresh'].values\n",
    "yvals = df_plotnew.loc[df_plotnew['label'] == 1, 'median'].values\n",
    "\n",
    "y1 = df_plotnew1.loc[df_plotnew1['label'] == 1, 'median'].values\n",
    "y2 = df_plotnew2.loc[df_plotnew2['label'] == 1, 'median'].values\n",
    "\n",
    "plt.plot(xvals, yvals, label='Label 1', lw=1.5, color='blue')\n",
    "plt.fill_between(xvals, y1, y2, alpha=0.3, label='IQR for Label 1', color='blue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5db1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b2696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "sns.lineplot(data=data, x='thresh', y='mean', hue='label', ax=ax)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "# Add a twin axis\n",
    "ax2 = ax.twinx()\n",
    "sns.lineplot(data=data, x='thresh', y='count', hue='label', ax=ax2, linestyle='--')\n",
    "\n",
    "# Customize the labels for clarity\n",
    "ax.set_ylabel('Mean (log-scale)')\n",
    "ax2.set_ylabel('Count')\n",
    "ax.set_xlabel('Threshold')\n",
    "\n",
    "ax.set_xlim(left = 9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1123dbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([np.min(mask) for mask in filtered_images], 'x')\n",
    "plt.plot([np.max(mask) for mask in filtered_images], 'o')\n",
    "plt.plot([np.mean(mask) for mask in filtered_images], '--')\n",
    "plt.plot([np.quantile(mask, 0.5) for mask in filtered_images], '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abda901",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_max = df_data.groupby(['thresh']).max()['mean'].reset_index()\n",
    "df_data_joined = df_data.merge(df_data_max, on='thresh', suffixes=('', '_max'))\n",
    "\n",
    "df_data_joined.loc[:, 'mean_rel'] = df_data_joined['mean'] / df_data_joined['mean_max']\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.lineplot(data=df_data_joined.loc[df_data['thresh'].isin(threshidx)], x='thresh', y='mean_rel', hue='label')\n",
    "# ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fd6752",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_max = df_data.groupby(['thresh']).max()['mean'].reset_index()\n",
    "df_data_joined = df_data.merge(df_data_max, on='thresh', suffixes=('', '_max'))\n",
    "\n",
    "df_data_joined.loc[:, 'mean_rel'] = df_data_joined['mean'] / df_data_joined['mean_max']\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.lineplot(data=df_data_joined.loc[df_data['thresh'].isin(threshidx)], x='thresh', y='mean_rel', hue='label')\n",
    "# ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083916b6",
   "metadata": {},
   "source": [
    "## STED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64905bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"region_data_sted.pkl\", \"rb\") as file:\n",
    "    data_loaded = pickle.load(file)\n",
    "\n",
    "thresholds = data_loaded['thresholds'].copy()\n",
    "numberfeatures = data_loaded['numberfeatures'].copy()\n",
    "smalldistances = data_loaded['smalldistances'].copy()\n",
    "totalsizes = data_loaded['totalsizes'].copy()\n",
    "sizes = data_loaded['sizes'].copy()\n",
    "\n",
    "del data_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e53f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i, size in tqdm(enumerate(sizes)):\n",
    "    for ti, t in enumerate(thresholds):\n",
    "        # fix the totalsize part, since we want to exclude the minimal image value\n",
    "        if t <= np.min(filtered_images[i]):\n",
    "            continue\n",
    "        stats = compute_boxplot_quantiles(size[ti])\n",
    "        if len(stats) > 0:\n",
    "            data.append({\n",
    "                'pos': i, \n",
    "                'label': labels[i],\n",
    "                'thresh': t,\n",
    "                'min': stats[0],\n",
    "                'Q1': stats[1],\n",
    "                'mean': stats[2],\n",
    "                'median': stats[3],\n",
    "                'Q3': stats[4],\n",
    "                'max': stats[5],\n",
    "                'count': len(size[ti])\n",
    "            }.copy())\n",
    "\n",
    "data = pd.DataFrame(data)\n",
    "data.loc[:, 'totalsize'] = [np.count_nonzero(filtered_images[i] > np.min(filtered_images[i]))\n",
    "                            for i in data['pos'].values]\n",
    "df_data = data.groupby(['label', 'thresh']).mean().reset_index()\n",
    "df_count = data.groupby(['label', 'thresh']).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f29bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datarel = data.copy()\n",
    "for col in ['min', 'Q1', 'mean', 'median', 'Q3', 'max']:\n",
    "    df_datarel[col] = df_datarel[col].astype(np.float64) \n",
    "    df_datarel[col] = df_datarel[col] / df_datarel['totalsize'].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bc094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshidx = set(df_count.loc[(df_count['mean'] > 1) & (df_count['label'] == 0), 'thresh'].values).\\\n",
    "    intersection(set(df_count.loc[(df_count['mean'] > 1) & (df_count['label'] == 0), 'thresh'].values))\n",
    "\n",
    "df_count.loc[df_count['thresh'].isin(threshidx), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569fccc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767d10e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "sns.lineplot(data=data.loc[data['thresh'] >= 3, :],\n",
    "             x='thresh', y='mean', hue='label', ax=ax)\n",
    "ax.set_yscale('log')\n",
    "# ax.set_xlim(left = 0)\n",
    "# Add a twin axis\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "# ax2.set_xlim(left = 0)\n",
    "sns.lineplot(data=data.loc[data['thresh'] >= 3, :],\n",
    "             x='thresh', y='count', hue='label', ax=ax2, linestyle='--')\n",
    "\n",
    "# Customize the labels for clarity\n",
    "ax.set_ylabel('Mean (log-scale, solid)')\n",
    "ax2.set_ylabel('Count (dashed)')\n",
    "ax.set_xlabel('Threshold')\n",
    "\n",
    "ax.set_xlim(right = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34c83fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "sns.lineplot(data=df_datarel.loc[df_datarel['thresh'] >= 3, :],\n",
    "             x='thresh', y='mean', hue='label', ax=ax)\n",
    "# ax.set_yscale('log')\n",
    "\n",
    "# Add a twin axis\n",
    "ax2 = ax.twinx()\n",
    "sns.lineplot(data=df_datarel.loc[df_datarel['thresh'] >= 3, :],\n",
    "             x='thresh', y='count', hue='label', ax=ax2, linestyle='--')\n",
    "\n",
    "# Customize the labels for clarity\n",
    "ax.set_ylabel('Mean (solid)')\n",
    "ax2.set_ylabel('Count (dashed)')\n",
    "ax.set_xlabel('Threshold')\n",
    "\n",
    "ax.set_xlim(right = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8528d6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "sns.lineplot(data=df_datarel.loc[df_datarel['thresh'] >= 3, :],\n",
    "             x='thresh', y='mean', hue='label', ax=ax)\n",
    "\n",
    "# Add a twin axis\n",
    "ax2 = ax.twinx()\n",
    "sns.lineplot(data=df_datarel.loc[df_datarel['thresh'] >= 3, :],\n",
    "             x='thresh', y='count', hue='label', ax=ax2, linestyle='--')\n",
    "\n",
    "# Customize the labels for clarity\n",
    "ax.set_ylabel('Mean (solid)')\n",
    "ax2.set_ylabel('Count (dashed)')\n",
    "ax.set_xlabel('Threshold')\n",
    "\n",
    "# Set the x-axis limit\n",
    "ax.set_xlim(right=60)\n",
    "\n",
    "# # For the secondary y-axis (count), set ticks 5 units apart\n",
    "start, end = ax2.get_ylim()\n",
    "# Set the y-axis limits based on the data (more explicit control)\n",
    "ax2.set_ylim(0, np.ceil(end / 10) * 10)\n",
    "# Use MaxNLocator for automatic, sensible tick placement\n",
    "ax2.yaxis.set_major_locator(MaxNLocator(integer=True, steps=[10]))\n",
    "\n",
    "# # For the secondary y-axis (count), set ticks 5 units apart\n",
    "start, end = ax.get_ylim()\n",
    "# Set the y-axis limits based on the data (more explicit control)\n",
    "ax.set_ylim(0, np.ceil(end / 10) * 10)\n",
    "# Use MaxNLocator for automatic, sensible tick placement\n",
    "ax.yaxis.set_major_locator(MaxNLocator(integer=True, steps=[10]))\n",
    "ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889f0b81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_nuclei_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
