{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d34835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gudhi as gd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.inputreader import read_segmented_images, persistence_writer_ensure_filesize\n",
    "from src.inputreader import read_persistence_files\n",
    "from src.auxfunctions import compute_vectorizations_all\n",
    "from src.auxfunctions import get_all_classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e894dc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input = Path('data_segmented')\n",
    "input_airyscan = data_input / 'Airyscan'\n",
    "input_sted = data_input / 'STED'\n",
    "\n",
    "data_pers = Path('data_processed')\n",
    "\n",
    "pers_sted = data_pers / 'persistence_sted'\n",
    "pers_airyscan = data_pers / 'persistence_airyscan'\n",
    "pers_sted_other = data_pers / 'persistence_sted' / 'other_preprocessing'\n",
    "pers_airyscan_other = data_pers / 'persistence_airyscan' / 'other_preprocessing'\n",
    "\n",
    "vec_sted = data_pers / 'vectorizations_sted'\n",
    "vec_airyscan = data_pers / 'vectorizations_airyscan'\n",
    "vec_sted_other = data_pers / 'vectorizations_sted' / 'other_preprocessing'\n",
    "vec_airyscan_other = data_pers / 'vectorizations_airyscan' / 'other_preprocessing'\n",
    "\n",
    "classification_path_preproc = data_pers / 'classification' / 'preprocsessing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "913009c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocessings = [\n",
    "    'raw',\n",
    "    'clip',\n",
    "    'clip_minmax',\n",
    "    'clip_gaussian2a_minmax',\n",
    "    'clip_gaussian2c_minmax', \n",
    "    'clip_gaussian4a_minmax',\n",
    "    'clip_gaussian4c_minmax',\n",
    "    'clip_minmax_gaussian2a_minmax',\n",
    "    'clip_minmax_gaussian2c_minmax', # this is the one used in the paper\n",
    "    'clip_minmax_gaussian4a_minmax',\n",
    "    'clip_minmax_gaussian4c_minmax'\n",
    "]\n",
    "\n",
    "preprocessing_in_paper = 'clip_minmax_gaussian2c_minmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90ed5e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_split_persistence_files(persistence_path,\n",
    "    persistence_path_other,\n",
    "    preproc, celltype):\n",
    "    \"\"\"\n",
    "    Check if the persistence files are split into multiple files.\n",
    "    \"\"\" \n",
    "    # check if file exist in its split form\n",
    "    if len(list(persistence_path.glob(f'*persistence_{celltype.lower()}_{preproc}.npz'))) >= 1:\n",
    "        return True\n",
    "    if len(list(persistence_path_other.glob(f'*persistence_{celltype.lower()}_{preproc}.npz'))) >= 1:\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182fffc0",
   "metadata": {},
   "source": [
    "# Comparison preprocessing in classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57315949",
   "metadata": {},
   "source": [
    "# compute persistence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d76fde",
   "metadata": {},
   "source": [
    "## STED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7978dd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:02<00:00, 213.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# get the metadata for the original files as well as the segmented files\n",
    "df_sted_metadata = pd.read_csv(data_input/ 'sted_df_metadata.csv', comment='#')\n",
    "\n",
    "masks, bounding_boxes, labels_str, labels, npzfiles = \\\n",
    "    read_segmented_images(input_sted, microscope='sted', replace_nan_with=0)\n",
    "\n",
    "df_labels = pd.DataFrame(labels_str, columns=['labels_str'])\n",
    "df_labels.loc[:, 'labels'] = labels\n",
    "df_labels.loc[:, 'id'] = np.arange(len(labels))\n",
    "df_labels.loc[:, 'microscope'] = 'sted'\n",
    "df_labels.loc[:, 'filename'] = [f.name for f in npzfiles]\n",
    "df_labels.to_csv(Path(data_pers, 'labels_persistence_sted.csv'),\n",
    "                 index=False)\n",
    "\n",
    "# get the physical pixel sizes for each image\n",
    "for filename in npzfiles:\n",
    "    assert len(df_sted_metadata.loc[df_sted_metadata['segmented_filename'] == filename.name, :]) == 1\n",
    "pixelsizes = [df_sted_metadata.loc[df_sted_metadata['segmented_filename'] == filename.name,\n",
    "                                   ['pixel_size_z', 'pixel_size_x', 'pixel_size_y']]\\\n",
    "                                    .values[0] for filename in npzfiles]\n",
    "pixelsizes = np.array(pixelsizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df41f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10cb8b57d6b46928ba306de31db68de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute persistence for preprocessing: clip\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13829d27c7d84a75aef85dd97583f460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/478 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sigma = 1\n",
    "\n",
    "for preproc in preprocessings:\n",
    "    # check if they have already been computed\n",
    "    if check_for_split_persistence_files(pers_sted, pers_sted_other, preproc, 'sted'):\n",
    "        continue\n",
    "\n",
    "    print(f'Compute persistence for preprocessing: {preproc}')\n",
    "\n",
    "    pers_all = {2: [[], []], 3: [[], [], []]}\n",
    "    for i, mask_loop in tqdm(enumerate(masks), total=len(masks)):\n",
    "        mask = mask_loop.astype(np.float64)\n",
    "        if np.any(np.isnan(mask)):\n",
    "            assert np.nanmin(mask) == 0\n",
    "            mask[np.isnan(mask)] = 0\n",
    "        mask_org = mask.copy()\n",
    "\n",
    "        if preproc != 'raw':\n",
    "            quant05 = np.nanquantile(mask[mask > np.min(mask)], 0.05)\n",
    "            quant95 = np.nanquantile(mask[mask > np.min(mask)], 0.95)\n",
    "            mask = np.clip(mask, quant05, quant95)\n",
    "        \n",
    "        if 'clip_minmax' in preproc:\n",
    "            mask = MinMaxScaler().fit_transform(mask.reshape(-1, 1)).reshape(mask.shape)\n",
    "        \n",
    "        if 'gaussian' in preproc and ('a_minmax' in preproc or 'a_mask0' in preproc or preproc.endswith('a')):\n",
    "            sigma_pixels = 1\n",
    "        elif 'gaussian' in preproc and ('b_minmax' in preproc or 'b_mask0' in preproc or preproc.endswith('b')):\n",
    "            # set the sigmas such that pixel_x and pixel_y are 1\n",
    "            sigma_pixels = pixelsizes[i].copy()\n",
    "            # x and y resolution should be the same\n",
    "            assert sigma_pixels[1] == sigma_pixels[2]\n",
    "            sigma_pixels /= sigma_pixels[1]\n",
    "        elif 'gaussian' in preproc and ('c_minmax' in preproc or 'c_mask0' in preproc or preproc.endswith('c')):\n",
    "            # set the sigmas such that pixel_z are 1\n",
    "            sigma_pixels = pixelsizes[i].copy()\n",
    "            # x and y resolution should be the same\n",
    "            assert sigma_pixels[1] == sigma_pixels[2]\n",
    "            sigma_pixels /= sigma_pixels[0]\n",
    "        \n",
    "        if 'gaussian' in preproc:\n",
    "            gaussian_truncate = \\\n",
    "                int(preproc[preproc.find('gaussian') + len('gaussian'):].split('_')[0][:-1])\n",
    "            mask = gaussian_filter(mask, sigma=sigma_pixels,\n",
    "                    truncate=gaussian_truncate, mode='constant', cval=0.0)\n",
    "    \n",
    "        if preproc.endswith('minmax') or preproc.endswith('minmax_mask0'):\n",
    "            mask = MinMaxScaler().fit_transform(mask.reshape(-1, 1)).reshape(mask.shape)\n",
    "        if 'mask0' in preproc:\n",
    "            mask[mask_org == 0] = 0\n",
    "        clipped_images = mask.copy()\n",
    "\n",
    "        for max_dim in [2, 3]:\n",
    "            if max_dim == 2:\n",
    "                cc = gd.CubicalComplex(top_dimensional_cells= -np.max(clipped_images.astype(np.float64), axis=0))\n",
    "            else:\n",
    "                cc = gd.CubicalComplex(top_dimensional_cells= -clipped_images.astype(np.float64))\n",
    "            cc.compute_persistence()\n",
    "\n",
    "            for dimi in range(max_dim):\n",
    "                persistence = cc.persistence_intervals_in_dimension(dimi)\n",
    "                pers_all[max_dim][dimi].append(persistence.copy())\n",
    "\n",
    "    pers_save = {'labels': labels_str}\n",
    "    for key in pers_all.keys():\n",
    "        for dim in range(len(pers_all[key])):\n",
    "            for i in range(len(pers_all[key][dim])):\n",
    "                newkey = f'pers-{key}_dim-{dim}_i-{i:04d}'\n",
    "                assert newkey not in pers_save\n",
    "                pers_save[newkey] = pers_all[key][dim][i].copy()\n",
    "                if np.shape(pers_all[key][dim][i])[0] < 10:\n",
    "                    print(newkey, key, dim, i, np.shape(pers_all[key][dim][i])[0])\n",
    "\n",
    "    if preproc == preprocessing_in_paper:\n",
    "        filepath = pers_sted/f'persistence_sted_{preproc}.npz'\n",
    "    else:\n",
    "        filepath = pers_sted_other/f'persistence_sted_{preproc}.npz'\n",
    "    np.savez_compressed(filepath, **pers_save)\n",
    "\n",
    "    # check the filesize and delete it if it is too large\n",
    "    # this is done to ensure the non-LFS filesize of github\n",
    "    if filepath.is_file() and filepath.stat().st_size / (1024*1024) < 95:\n",
    "        persistence_writer_ensure_filesize(filepath,\n",
    "            maxfilesize=95, lowerlimit=90,\n",
    "            split_names='splitfiles',\n",
    "            pers2d3d=['pers-2', 'pers-3'])\n",
    "        filepath.unlink()\n",
    "    del pers_save\n",
    "    del pers_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78474518",
   "metadata": {},
   "source": [
    "## airyscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e91a099",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91/91 [00:01<00:00, 62.21it/s]\n"
     ]
    }
   ],
   "source": [
    "df_airy_metadata = pd.read_csv(data_input / 'airyscan_df_metadata.csv')\n",
    "masks, bounding_boxes, labels_str, labels, npzfiles = read_segmented_images(input_airyscan, microscope='airyscan')\n",
    "\n",
    "df_labels = pd.DataFrame(labels_str, columns=['labels_str'])\n",
    "df_labels.loc[:, 'labels'] = labels\n",
    "df_labels.loc[:, 'id'] = np.arange(len(labels))\n",
    "df_labels.loc[:, 'microscope'] = 'airyscan'\n",
    "df_labels.loc[:, 'filename'] = [f.name for f in npzfiles]\n",
    "\n",
    "df_labels.to_csv(Path(data_pers, 'labels_persistence_airyscan.csv'),\n",
    "                 index=False)\n",
    "\n",
    "pixelsizes = [df_airy_metadata.loc[df_airy_metadata['segmented_filename'] == filename.name,\n",
    "              ['pixel_size_z', 'pixel_size_x', 'pixel_size_y']]\\\n",
    "              .values[0] for filename in npzfiles]\n",
    "pixelsizes = np.array(pixelsizes)\n",
    "\n",
    "assert np.all(pixelsizes[:, 1] == pixelsizes[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89fcbf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for preproc in preprocessings:\n",
    "    if check_for_split_persistence_files(pers_airyscan, pers_airyscan_other, preproc, 'airyscan'):\n",
    "            continue\n",
    "\n",
    "    print(f'Compute persistence for preprocessing: {preproc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9df40e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1\n",
    "\n",
    "for preproc in preprocessings:\n",
    "    # check if the persistence files already exist\n",
    "    if check_for_split_persistence_files(pers_airyscan, pers_airyscan_other, preproc, 'airyscan'):\n",
    "        continue\n",
    "\n",
    "    print(f'Compute persistence for preprocessing: {preproc}')\n",
    "\n",
    "    pers_all = {2: [[], []], 3: [[], [], []]}\n",
    "    for i, mask_loop in tqdm(enumerate(masks), total=len(masks)):\n",
    "        mask = mask_loop.astype(np.float64)\n",
    "        if np.any(np.isnan(mask)):\n",
    "            assert np.nanmin(mask) == 0\n",
    "            mask[np.isnan(mask)] = 0\n",
    "        mask_org = mask.copy()\n",
    "\n",
    "        if preproc != 'raw':\n",
    "            quant05 = np.nanquantile(mask[mask > np.min(mask)], 0.05)\n",
    "            quant95 = np.nanquantile(mask[mask > np.min(mask)], 0.95)\n",
    "            mask = np.clip(mask, quant05, quant95)\n",
    "        \n",
    "        if 'clip_minmax' in preproc:\n",
    "            mask = MinMaxScaler().fit_transform(mask.reshape(-1, 1)).reshape(mask.shape)\n",
    "        \n",
    "        if 'gaussian' in preproc and ('a_minmax' in preproc or 'a_mask0' in preproc or preproc.endswith('a')):\n",
    "            sigma_pixels = 1\n",
    "        elif 'gaussian' in preproc and ('b_minmax' in preproc or 'b_mask0' in preproc or preproc.endswith('b')):\n",
    "            # set the sigmas such that pixel_x and pixel_y are 1\n",
    "            sigma_pixels = pixelsizes[i].copy()\n",
    "            # x and y resolution should be the same\n",
    "            assert sigma_pixels[1] == sigma_pixels[2]\n",
    "            sigma_pixels /= sigma_pixels[1]\n",
    "        elif 'gaussian' in preproc and ('c_minmax' in preproc or 'c_mask0' in preproc or preproc.endswith('c')):\n",
    "            # set the sigmas such that pixel_z are 1\n",
    "            sigma_pixels = pixelsizes[i].copy()\n",
    "            # x and y resolution should be the same\n",
    "            assert sigma_pixels[1] == sigma_pixels[2]\n",
    "            sigma_pixels /= sigma_pixels[0]\n",
    "        \n",
    "        if 'gaussian' in preproc:\n",
    "            gaussian_truncate = \\\n",
    "                int(preproc[preproc.find('gaussian') + len('gaussian'):].split('_')[0][:-1])\n",
    "            mask = gaussian_filter(mask, sigma=sigma_pixels,\n",
    "                    truncate=gaussian_truncate, mode='constant', cval=0.0)\n",
    "        \n",
    "        if preproc.endswith('minmax') or preproc.endswith('minmax_mask0'):\n",
    "            mask = MinMaxScaler().fit_transform(mask.reshape(-1, 1)).reshape(mask.shape)\n",
    "        if 'mask0' in preproc:\n",
    "            mask[mask_org == 0] = 0\n",
    "        clipped_images = mask.copy()\n",
    "\n",
    "        for max_dim in [2, 3]:\n",
    "            if max_dim == 2:\n",
    "                cc = gd.CubicalComplex(top_dimensional_cells= -np.max(clipped_images.astype(np.float64), axis=0))\n",
    "            else:\n",
    "                cc = gd.CubicalComplex(top_dimensional_cells= -clipped_images.astype(np.float64))\n",
    "            cc.compute_persistence()\n",
    "\n",
    "            for dimi in range(max_dim):\n",
    "                persistence = cc.persistence_intervals_in_dimension(dimi)\n",
    "                pers_all[max_dim][dimi].append(persistence.copy())\n",
    "\n",
    "    pers_save = {'labels': labels_str}\n",
    "    for key in pers_all.keys():\n",
    "        for dim in range(len(pers_all[key])):\n",
    "            for i in range(len(pers_all[key][dim])):\n",
    "                newkey = f'pers-{key}_dim-{dim}_i-{i:04d}'\n",
    "                assert newkey not in pers_save\n",
    "                pers_save[newkey] = pers_all[key][dim][i].copy()\n",
    "                if np.shape(pers_all[key][dim][i])[0] < 10:\n",
    "                    print(newkey, key, dim, i, np.shape(pers_all[key][dim][i])[0])\n",
    "\n",
    "    if preproc == preprocessing_in_paper:\n",
    "        filepath = pers_airyscan / f'persistence_airyscan_{preproc}.npz'\n",
    "    else:\n",
    "        filepath = pers_airyscan_other / f'persistence_airyscan_{preproc}.npz'\n",
    "    np.savez_compressed(filepath, **pers_save)\n",
    "    print(filepath)\n",
    "\n",
    "    # check the filesize and delete it if it is too large\n",
    "    # this is done to ensure the non LFS filesize of github\n",
    "    if filepath.is_file() and filepath.stat().st_size / (1024*1024) < 95:\n",
    "        persistence_writer_ensure_filesize(filepath,\n",
    "            maxfilesize=95, lowerlimit=90,\n",
    "            split_names='splitfiles',\n",
    "            pers2d3d=['pers-2', 'pers-3'])\n",
    "        filepath.unlink()\n",
    "    del pers_save\n",
    "    del pers_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "804d80b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cef2635457e54a2a985c46180c962eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for preproc in tqdm(preprocessings):\n",
    "    # check if the persistence files already exist\n",
    "    if (preproc == preprocessing_in_paper\n",
    "        and Path(pers_airyscan/f'persistence_airyscan_{preproc}.npz').exists()):\n",
    "        continue\n",
    "    if Path(pers_airyscan_other/f'persistence_airyscan_{preproc}.npz').exists():\n",
    "        continue\n",
    "\n",
    "    if preproc == preprocessing_in_paper:\n",
    "        filepath = pers_airyscan / f'persistence_airyscan_{preproc}.npz'\n",
    "    else:\n",
    "        filepath = pers_airyscan_other / f'persistence_airyscan_{preproc}.npz'\n",
    "\n",
    "    print(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4a4895",
   "metadata": {},
   "source": [
    "# compute classification perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af85c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This computes the vectorizations for all persistence files for the different preprocessing steps\n",
    "\n",
    "# for microscope in ['sted', 'airyscan']:\n",
    "#     for preprocessing in preprocessings:\n",
    "#         if preprocessing == preprocessing_in_paper:\n",
    "#             if microscope.lower() == 'sted':\n",
    "#                 pers_folder = pers_sted\n",
    "#                 vect_folder = vec_sted\n",
    "#             elif microscope.lower() == 'airyscan':\n",
    "#                 pers_folder = pers_airyscan\n",
    "#                 vect_folder = vec_airyscan\n",
    "#             else:\n",
    "#                 raise ValueError('Microscope not recognized!')\n",
    "        \n",
    "#         else:\n",
    "#             if microscope.lower() == 'sted':\n",
    "#                 pers_folder = pers_sted_other\n",
    "#                 vect_folder = vec_sted_other\n",
    "#             elif microscope.lower() == 'airyscan':\n",
    "#                 pers_folder = pers_airyscan_other\n",
    "#                 vect_folder = vec_airyscan_other\n",
    "#             else:\n",
    "#                 raise ValueError('Microscope not recognized!')\n",
    "\n",
    "#         pers_all, keys = read_persistence_files(pers_folder, preprocessing, return_keys=True)\n",
    "#         if pers_all is None:\n",
    "#             print('No persistence files for this preprocessing steps found!')\n",
    "#         df_labels = pd.read_csv(data_pers / f'labels_persistence_{microscope.lower()}.csv')\n",
    "#         labels = df_labels['labels'].values\n",
    "\n",
    "#         df_vectorizations = compute_vectorizations_all(labels, pers_all, resolution_pi=20, bandwidth=4, resolution_bc=250)\n",
    "#         df_vectorizations.to_csv(vect_folder / f'vectorizations_all_{microscope.lower()}_{preprocessing}.csv',\n",
    "#                                 index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7220af",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = 'clip_minmax_gaussian2c_minmax'\n",
    "df_labels = pd.read_csv(data_pers / 'labels_persistence_airyscan.csv')\n",
    "labels = df_labels['labels'].values\n",
    "\n",
    "get_all_classifications(preprocessing,\n",
    "    pers_sted, \n",
    "    classification_path_preproc,\n",
    "    labels,\n",
    "    runs=10, train_percent='70', run=0,\n",
    "    nameappend=f'preprocessing-',\n",
    "    saveasfile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea5ac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = 'clip_minmax_gaussian2c_minmax'\n",
    "df_labels = pd.read_csv(data_pers / 'labels_persistence_airyscan.csv')\n",
    "labels = df_labels['labels'].values\n",
    "\n",
    "get_all_classifications(preprocessing,\n",
    "    pers_sted, \n",
    "    classification_path_preproc,\n",
    "    labels,\n",
    "    runs=10, train_percent='70', run=0,\n",
    "    nameappend=f'preprocessing-',\n",
    "    saveasfile=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_nuclei_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
