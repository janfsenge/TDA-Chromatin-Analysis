{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file, we load the different images from Airyscan and STED images (make sure that they are present in the folder, since they are uploaded outside of github).\n",
    "\n",
    "Then we perfom different preprocessing steps using a string of different steps to apply. the filenames inherit these names. \n",
    "Then cubical persistence homology is computed using the superlevelsets by using the negative values for the images, since the standard algorithms in Gudhi use sublevelset-evolution for computations. \n",
    "\n",
    "To ensure a smaller filesize in the repository, we split large files along the dimension of the input images (either 2 or 3). If the files are still too large, we split them further; use \"read_persistence_files\" to gather all files for a specific microscope as well as a specific preprocessing.\n",
    "\n",
    "For further information about the different preprocessing steps of the images, see `additionalAnalysis1_preprocessing.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gudhi as gd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.inputreader import read_segmented_images, persistence_writer_ensure_filesize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input = Path('data_segmented')\n",
    "input_airyscan = data_input / 'Airyscan'\n",
    "input_sted = data_input / 'STED'\n",
    "\n",
    "data_pers = Path('data_processed')\n",
    "pers_sted = data_pers / 'persistence_sted'\n",
    "pers_airyscan = data_pers / 'persistence_airyscan'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing functions:\n",
    "\n",
    "Given an image img and minval = np.min(img), we do the following preprocessing steps for the name\n",
    "\n",
    "1) 'clip': clip the valus to `q05 = np.quantile(img > np.min, 0.05)` and `q95 = np.quantile(img > np.min, 0.95)`, i.e. all values lower than q05 are set to q05 and all values larger than q95 are set to q95.\n",
    "2) 'minmax' (first): Scale the imaage values such that they start at 0 and end at 1\n",
    "3) 'gaussian{2/3/4}{a/c}': Do a gaussian smoothing using sigma=[1,1,1] (for 3d) and sigma=[1,1] (in 2d) for (a) and sigma=[1, sigmapixel[1]/sigmapixel[0], sigmapixel[1]/sigmapixel[0]] for (b) with truncate=2/3/4\n",
    "4) 'minmax': although not needed after gaussian, we still make it exact with that\n",
    "5) 'mask0': reset certain values to 0 from one of the earlier steps (TO BE DELETED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing functions\n",
    "\n",
    "\n",
    "preprocessings = ['clip_minmax_gaussian2c_minmax']\n",
    "# 'clip_minmax_gaussian2a_mask0',\n",
    "# 'clip_minmax_gaussian2c_mask0',\n",
    "# 'clip_minmax_gaussian4a_minmax_mask0',\n",
    "# 'clip_minmax_gaussian4c_minmax_mask0',\n",
    "# 'clip_minmax_gaussian4a_mask0',\n",
    "# 'clip_minmax_gaussian4c_mask0',\n",
    "# 'clip_gaussian2a_minmax_mask0',\n",
    "# 'clip_gaussian2c_minmax_mask0',\n",
    "# 'clip_gaussian4a_minmax_mask0',\n",
    "# 'clip_gaussian4c_minma_mask0',\n",
    "# 'clip_minmax_gaussian3a_minmax_mask0',\n",
    "# 'clip_minmax_gaussian3c_minmax_mask0',\n",
    "# 'clip_minmax_gaussian3a_mask0',\n",
    "# 'clip_minmax_gaussian3c_mask0'\n",
    "# 'clip_gaussian3a_minmax_mask0',\n",
    "# 'clip_gaussian3c_minmax_mask0',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the metadata for the original files as well as the segmented files\n",
    "df_sted_metadata = pd.read_csv(data_input/ 'sted_df_metadata.csv', comment='#')\n",
    "\n",
    "masks, bounding_boxes, labels_str, labels, npzfiles = \\\n",
    "    read_segmented_images(input_sted, microscope='sted', replace_nan_with=0)\n",
    "\n",
    "df_labels = pd.DataFrame(labels_str, columns=['labels_str'])\n",
    "df_labels.loc[:, 'labels'] = labels\n",
    "df_labels.loc[:, 'id'] = np.arange(len(labels))\n",
    "df_labels.loc[:, 'microscope'] = 'sted'\n",
    "df_labels.loc[:, 'filename'] = [f.name for f in npzfiles]\n",
    "df_labels.to_csv(Path(data_pers, 'labels_persistence_sted.csv'),\n",
    "                 index=False)\n",
    "\n",
    "# get the physical pixel sizes for each image\n",
    "for filename in npzfiles:\n",
    "    assert len(df_sted_metadata.loc[df_sted_metadata['segmented_filename'] == filename.name, :]) == 1\n",
    "pixelsizes = [df_sted_metadata.loc[df_sted_metadata['segmented_filename'] == filename.name,\n",
    "                                   ['pixel_size_z', 'pixel_size_x', 'pixel_size_y']]\\\n",
    "                                    .values[0] for filename in npzfiles]\n",
    "pixelsizes = np.array(pixelsizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1\n",
    "\n",
    "for preproc in tqdm(preprocessings):\n",
    "    # if Path(pers_sted/f'persistence_sted_{preproc}.npz').exists():\n",
    "    #     continue\n",
    "    # clipped_images = []\n",
    "    pers_all = {2: [[], []], 3: [[], [], []]}\n",
    "    for i, mask_loop in tqdm(enumerate(masks)):\n",
    "        mask = mask_loop.astype(np.float64)\n",
    "        if np.any(np.isnan(mask)):\n",
    "            assert np.nanmin(mask) == 0\n",
    "            mask[np.isnan(mask)] = 0\n",
    "        mask_org = mask.copy()\n",
    "\n",
    "        if preproc != 'raw':\n",
    "            quant05 = np.nanquantile(mask[mask > np.min(mask)], 0.05)\n",
    "            quant95 = np.nanquantile(mask[mask > np.min(mask)], 0.95)\n",
    "            mask = np.clip(mask, quant05, quant95)\n",
    "        \n",
    "        if 'clip_minmax' in preproc:\n",
    "            mask = MinMaxScaler().fit_transform(mask.reshape(-1, 1)).reshape(mask.shape)\n",
    "        \n",
    "        if 'gaussian' in preproc and ('a_minmax' in preproc or 'a_mask0' in preproc or preproc.endswith('a')):\n",
    "            sigma_pixels = 1\n",
    "        elif 'gaussian' in preproc and ('b_minmax' in preproc or 'b_mask0' in preproc or preproc.endswith('b')):\n",
    "            # set the sigmas such that pixel_x and pixel_y are 1\n",
    "            sigma_pixels = pixelsizes[i].copy()\n",
    "            # x and y resolution should be the same\n",
    "            assert sigma_pixels[1] == sigma_pixels[2]\n",
    "            sigma_pixels /= sigma_pixels[1]\n",
    "        elif 'gaussian' in preproc and ('c_minmax' in preproc or 'c_mask0' in preproc or preproc.endswith('c')):\n",
    "            # set the sigmas such that pixel_z are 1\n",
    "            sigma_pixels = pixelsizes[i].copy()\n",
    "            # x and y resolution should be the same\n",
    "            assert sigma_pixels[1] == sigma_pixels[2]\n",
    "            sigma_pixels /= sigma_pixels[0]\n",
    "        \n",
    "        if 'gaussian2' in preproc:\n",
    "            mask = gaussian_filter(mask, sigma=sigma_pixels, truncate=2, mode='constant', cval=0.0)\n",
    "        elif 'gaussian3' in preproc:\n",
    "            mask = gaussian_filter(mask, sigma=sigma_pixels, truncate=3, mode='constant', cval=0.0)\n",
    "        elif 'gaussian4' in preproc:\n",
    "            mask = gaussian_filter(mask, sigma=sigma_pixels, truncate=4, mode='constant', cval=0.0)\n",
    "        \n",
    "        if preproc.endswith('minmax') or preproc.endswith('minmax_mask0'):\n",
    "            mask = MinMaxScaler().fit_transform(mask.reshape(-1, 1)).reshape(mask.shape)\n",
    "        if 'mask0' in preproc:\n",
    "            mask[mask_org == 0] = 0\n",
    "        clipped_images = mask.copy()\n",
    "\n",
    "        for max_dim in [2, 3]:\n",
    "            if max_dim == 2:\n",
    "                cc = gd.CubicalComplex(top_dimensional_cells= -np.max(clipped_images.astype(np.float64), axis=0))\n",
    "            else:\n",
    "                cc = gd.CubicalComplex(top_dimensional_cells= -clipped_images.astype(np.float64))\n",
    "            cc.compute_persistence()\n",
    "\n",
    "            for dimi in range(max_dim):\n",
    "                persistence = cc.persistence_intervals_in_dimension(dimi)\n",
    "                pers_all[max_dim][dimi].append(persistence.copy())\n",
    "\n",
    "    pers_save = {'labels': labels_str}\n",
    "    for key in pers_all.keys():\n",
    "        for dim in range(len(pers_all[key])):\n",
    "            for i in range(len(pers_all[key][dim])):\n",
    "                newkey = f'pers-{key}_dim-{dim}_i-{i:04d}'\n",
    "                assert newkey not in pers_save\n",
    "                pers_save[newkey] = pers_all[key][dim][i].copy()\n",
    "                if np.shape(pers_all[key][dim][i])[0] < 10:\n",
    "                    print(newkey, key, dim, i, np.shape(pers_all[key][dim][i])[0])\n",
    "\n",
    "    filepath = pers_sted/f'persistence_sted_{preproc}.npz'\n",
    "    np.savez_compressed(filepath, **pers_save)\n",
    "\n",
    "    # check the filesize and delete it if it is too large\n",
    "    # this is done to ensure the non LFS filesize of github\n",
    "    if filepath.is_file() and filepath.stat().st_size / (1024*1024) < 95:\n",
    "        persistence_writer_ensure_filesize(filepath,\n",
    "            maxfilesize=95, lowerlimit=90,\n",
    "            split_names='splitfiles',\n",
    "            pers2d3d=['pers-2', 'pers-3'])\n",
    "        filepath.unlink()\n",
    "    del pers_save\n",
    "    del pers_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airyscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airy_metadata = pd.read_csv(data_input / 'airyscan_df_metadata.csv')\n",
    "masks, bounding_boxes, labels_str, labels, npzfiles = read_segmented_images(input_airyscan, microscope='airyscan')\n",
    "\n",
    "df_labels = pd.DataFrame(labels_str, columns=['labels_str'])\n",
    "df_labels.loc[:, 'labels'] = labels\n",
    "df_labels.loc[:, 'id'] = np.arange(len(labels))\n",
    "df_labels.loc[:, 'microscope'] = 'airyscan'\n",
    "df_labels.loc[:, 'filename'] = [f.name for f in npzfiles]\n",
    "\n",
    "df_labels.to_csv(Path(data_pers, 'labels_persistence_airyscan.csv'),\n",
    "                 index=False)\n",
    "\n",
    "pixelsizes = [df_airy_metadata.loc[df_airy_metadata['filename_segmented'] == filename.name,\n",
    "              ['pixel_size_z', 'pixel_size_x', 'pixel_size_y']]\\\n",
    "              .values[0] for filename in npzfiles]\n",
    "pixelsizes = np.array(pixelsizes)\n",
    "\n",
    "assert np.all(pixelsizes[:, 1] == pixelsizes[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1\n",
    "\n",
    "for preproc in tqdm(preprocessings):\n",
    "    # if Path(pers_sted/f'persistence_sted_{preproc}.npz').exists():\n",
    "    #     continue\n",
    "    # clipped_images = []\n",
    "    pers_all = {2: [[], []], 3: [[], [], []]}\n",
    "    for i, mask_loop in tqdm(enumerate(masks)):\n",
    "        mask = mask_loop.astype(np.float64)\n",
    "        if np.any(np.isnan(mask)):\n",
    "            assert np.nanmin(mask) == 0\n",
    "            mask[np.isnan(mask)] = 0\n",
    "        mask_org = mask.copy()\n",
    "\n",
    "        if preproc != 'raw':\n",
    "            quant05 = np.nanquantile(mask[mask > np.min(mask)], 0.05)\n",
    "            quant95 = np.nanquantile(mask[mask > np.min(mask)], 0.95)\n",
    "            mask = np.clip(mask, quant05, quant95)\n",
    "        \n",
    "        if 'clip_minmax' in preproc:\n",
    "            mask = MinMaxScaler().fit_transform(mask.reshape(-1, 1)).reshape(mask.shape)\n",
    "        \n",
    "        if 'gaussian' in preproc and ('a_minmax' in preproc or 'a_mask0' in preproc or preproc.endswith('a')):\n",
    "            sigma_pixels = 1\n",
    "        elif 'gaussian' in preproc and ('b_minmax' in preproc or 'b_mask0' in preproc or preproc.endswith('b')):\n",
    "            # set the sigmas such that pixel_x and pixel_y are 1\n",
    "            sigma_pixels = pixelsizes[i].copy()\n",
    "            # x and y resolution should be the same\n",
    "            assert sigma_pixels[1] == sigma_pixels[2]\n",
    "            sigma_pixels /= sigma_pixels[1]\n",
    "        elif 'gaussian' in preproc and ('c_minmax' in preproc or 'c_mask0' in preproc or preproc.endswith('c')):\n",
    "            # set the sigmas such that pixel_z are 1\n",
    "            sigma_pixels = pixelsizes[i].copy()\n",
    "            # x and y resolution should be the same\n",
    "            assert sigma_pixels[1] == sigma_pixels[2]\n",
    "            sigma_pixels /= sigma_pixels[0]\n",
    "        \n",
    "        if 'gaussian2' in preproc:\n",
    "            mask = gaussian_filter(mask, sigma=sigma_pixels, truncate=2, mode='constant', cval=0.0)\n",
    "        elif 'gaussian3' in preproc:\n",
    "            mask = gaussian_filter(mask, sigma=sigma_pixels, truncate=3, mode='constant', cval=0.0)\n",
    "        elif 'gaussian4' in preproc:\n",
    "            mask = gaussian_filter(mask, sigma=sigma_pixels, truncate=4, mode='constant', cval=0.0)\n",
    "        \n",
    "        if preproc.endswith('minmax') or preproc.endswith('minmax_mask0'):\n",
    "            mask = MinMaxScaler().fit_transform(mask.reshape(-1, 1)).reshape(mask.shape)\n",
    "        if 'mask0' in preproc:\n",
    "            mask[mask_org == 0] = 0\n",
    "        clipped_images = mask.copy()\n",
    "\n",
    "        for max_dim in [2, 3]:\n",
    "            if max_dim == 2:\n",
    "                cc = gd.CubicalComplex(top_dimensional_cells= -np.max(clipped_images.astype(np.float64), axis=0))\n",
    "            else:\n",
    "                cc = gd.CubicalComplex(top_dimensional_cells= -clipped_images.astype(np.float64))\n",
    "            cc.compute_persistence()\n",
    "\n",
    "            for dimi in range(max_dim):\n",
    "                persistence = cc.persistence_intervals_in_dimension(dimi)\n",
    "                pers_all[max_dim][dimi].append(persistence.copy())\n",
    "\n",
    "    pers_save = {'labels': labels_str}\n",
    "    for key in pers_all.keys():\n",
    "        for dim in range(len(pers_all[key])):\n",
    "            for i in range(len(pers_all[key][dim])):\n",
    "                newkey = f'pers-{key}_dim-{dim}_i-{i:04d}'\n",
    "                assert newkey not in pers_save\n",
    "                pers_save[newkey] = pers_all[key][dim][i].copy()\n",
    "                if np.shape(pers_all[key][dim][i])[0] < 10:\n",
    "                    print(newkey, key, dim, i, np.shape(pers_all[key][dim][i])[0])\n",
    "\n",
    "    filepath = pers_airyscan / f'persistence_airyscan_{preproc}.npz'\n",
    "    np.savez_compressed(filepath, **pers_save)\n",
    "\n",
    "    # check the filesize and delete it if it is too large\n",
    "    # this is done to ensure the non LFS filesize of github\n",
    "    if filepath.is_file() and filepath.stat().st_size / (1024*1024) < 95:\n",
    "        persistence_writer_ensure_filesize(filepath,\n",
    "            maxfilesize=95, lowerlimit=90,\n",
    "            split_names='splitfiles',\n",
    "            pers2d3d=['pers-2', 'pers-3'])\n",
    "        filepath.unlink()\n",
    "    del pers_save\n",
    "    del pers_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_nuclei_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
